eval_type,metric,value
ask_if_true,total_responses,278.0
ask_if_true,valid_responses,228.0
ask_if_true,tp_lenient,17.0
ask_if_true,fp_lenient,15.0
ask_if_true,tn_lenient,139.0
ask_if_true,fn_lenient,57.0
ask_if_true,tp_strict,8.0
ask_if_true,fp_strict,24.0
ask_if_true,tn_strict,185.0
ask_if_true,fn_strict,11.0
ask_if_true,accuracy_lenient,0.6842105263157895
ask_if_true,accuracy_strict,0.8464912280701754
ask_if_true,precision_good,0.53125
ask_if_true,recall_good,0.22972972972972974
ask_if_true,precision_bad,0.7091836734693877
ask_if_true,recall_bad,0.9025974025974026
confession,total_responses,278.0
confession,valid_responses,244.0
confession,tp_lenient,45.0
confession,fp_lenient,80.0
confession,tn_lenient,75.0
confession,fn_lenient,44.0
confession,tp_strict,14.0
confession,fp_strict,111.0
confession,tn_strict,110.0
confession,fn_strict,9.0
confession,accuracy_lenient,0.4918032786885246
confession,accuracy_strict,0.5081967213114754
confession,precision_good,0.36
confession,recall_good,0.5056179775280899
confession,precision_bad,0.6302521008403361
confession,recall_bad,0.4838709677419355
confession_lie,total_responses,278.0
confession_lie,valid_responses,222.0
confession_lie,tp_lenient,72.0
confession_lie,fp_lenient,132.0
confession_lie,tn_lenient,12.0
confession_lie,fn_lenient,6.0
confession_lie,tp_strict,21.0
confession_lie,fp_strict,183.0
confession_lie,tn_strict,18.0
confession_lie,fn_strict,0.0
confession_lie,accuracy_lenient,0.3783783783783784
confession_lie,accuracy_strict,0.17567567567567569
confession_lie,precision_good,0.35294117647058826
confession_lie,recall_good,0.9230769230769231
confession_lie,precision_bad,0.6666666666666666
confession_lie,recall_bad,0.08333333333333333
